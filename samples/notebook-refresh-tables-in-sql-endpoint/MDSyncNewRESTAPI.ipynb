{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c0656-c847-4935-a3eb-85aec0efc667",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import notebookutils \n",
    "import sempy.fabric as fabric \n",
    "from sempy.fabric.exceptions import FabricHTTPException, WorkspaceNotFoundException \n",
    "\n",
    "workspace_id=spark.conf.get(\"trident.workspace.id\")\n",
    "lakehouse_id=spark.conf.get(\"trident.lakehouse.id\")\n",
    "\n",
    "#Instantiate the client\n",
    "client = fabric.FabricRestClient()\n",
    "\n",
    "# This is the SQL endpoint I want to sync with the lakehouse, this needs to be the GUI\n",
    "sqlendpoint = fabric.FabricRestClient().get(f\"/v1/workspaces/{workspace_id}/lakehouses/{lakehouse_id}\").json()['properties']['sqlEndpointProperties']['id']\n",
    "\n",
    "# URI for the call \n",
    "#uri = f\"v1/workspaces/{workspace_id}/sqlEndpoints/{sqlendpoint}/refreshMetadata?preview=true\" #preview=true is no longer needed, the result is slightly different with preview=true\n",
    "uri = f\"v1/workspaces/{workspace_id}/sqlEndpoints/{sqlendpoint}/refreshMetadata\" \n",
    "\n",
    "# This is the action, we want to take \n",
    "# payload = {} # empty payload, all tables\n",
    "# Example of setting a timeout\n",
    "payload = { \"timeout\": {\"timeUnit\": \"Seconds\", \"value\": \"60\"}  }  # Setting a timeout for the REST call\n",
    "\n",
    "try:\n",
    "    response = client.post(uri,json= payload, lro_wait = True) \n",
    "    sync_status = json.loads(response.text)\n",
    "    display(sync_status)\n",
    "except Exception as e: print(e)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "f6d19585-99bf-40a8-bfe2-d6ece853538e",
    "default_lakehouse_name": "lakehouse",
    "default_lakehouse_workspace_id": "d62d3af9-da91-4500-ac8b-78cd389e34cd",
    "known_lakehouses": [
     {
      "id": "f6d19585-99bf-40a8-bfe2-d6ece853538e"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
