{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1690e2-4c4e-4eb4-ab99-c303119f9c6a",
   "metadata": {
    "cellStatus": "{\"System Administrator\":{\"session_start_time\":\"2025-07-11T10:39:14.3754399Z\",\"execution_start_time\":\"2025-07-11T10:39:25.6466912Z\",\"execution_finish_time\":\"2025-07-11T10:39:26.0570192Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-07-11T10:39:26.0570192Z",
       "execution_start_time": "2025-07-11T10:39:25.6466912Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "0948dae2-e82d-4b2d-8f71-f59a4e321b9a",
       "queued_time": "2025-07-11T10:39:14.3744167Z",
       "session_id": "f92ff0f1-c298-45e6-bda4-9ad94e766612",
       "session_start_time": "2025-07-11T10:39:14.3754399Z",
       "spark_pool": null,
       "state": "finished",
       "statement_id": 3,
       "statement_ids": [
        3
       ]
      },
      "text/plain": [
       "StatementMeta(, f92ff0f1-c298-45e6-bda4-9ad94e766612, 3, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from delta.tables import *\n",
    "from notebookutils import mssparkutils\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from pyspark.sql.functions import col, when, from_json, date_format, lit, row_number,max, lower\n",
    "from pyspark.sql.types import StructType, StringType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c40ac-00e9-42f9-8c10-502e81702d51",
   "metadata": {
    "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-07-11T10:39:26.0591634Z\",\"execution_finish_time\":\"2025-07-11T10:39:26.3994384Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-07-11T10:39:26.3994384Z",
       "execution_start_time": "2025-07-11T10:39:26.0591634Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "3765a5f2-c2da-40bb-aee1-7692febeecf5",
       "queued_time": "2025-07-11T10:39:17.0441716Z",
       "session_id": "f92ff0f1-c298-45e6-bda4-9ad94e766612",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 4,
       "statement_ids": [
        4
       ]
      },
      "text/plain": [
       "StatementMeta(, f92ff0f1-c298-45e6-bda4-9ad94e766612, 4, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fromMonth = 0 #-1, -2,... from datenow -1 day \n",
    "toMonth = 0 #-1, -2,... from datenow -1 day\n",
    "rawSourcePath = \"Files/focuscost\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b716fa9-6b0f-4159-bcea-e22256a8052d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8b57c4-a4eb-48b5-baa5-861a8444c023",
   "metadata": {
    "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-07-11T10:39:26.4016266Z\",\"execution_finish_time\":\"2025-07-11T10:39:26.7086809Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-07-11T10:39:26.7086809Z",
       "execution_start_time": "2025-07-11T10:39:26.4016266Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "8ab8d800-6b9f-44fa-bba2-df50bbeedadb",
       "queued_time": "2025-07-11T10:39:19.1984173Z",
       "session_id": "f92ff0f1-c298-45e6-bda4-9ad94e766612",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 5,
       "statement_ids": [
        5
       ]
      },
      "text/plain": [
       "StatementMeta(, f92ff0f1-c298-45e6-bda4-9ad94e766612, 5, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_first_parquet_file(path):\n",
    "    \"\"\"\n",
    "    Recursively search for the first .parquet file in the given directory.\n",
    "    Args:\n",
    "        path (str): The root directory to start the search.\n",
    "    Returns:\n",
    "        str or None: The full path to the first .parquet file found, or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for entry in mssparkutils.fs.ls(path):\n",
    "            if entry.isFile and entry.name.endswith(\".parquet\"):\n",
    "                return entry.path\n",
    "            elif entry.isDir:\n",
    "                result = find_first_parquet_file(entry.path)\n",
    "                if result:\n",
    "                    return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing {path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def generate_wildcard_path(full_path: str, raw_source_path: str, snapshot_folder: str) -> str:\n",
    "    # Find the index where the raw source path starts\n",
    "    idx = full_path.find(raw_source_path)\n",
    "    if idx == -1:\n",
    "        raise ValueError(\"rawSourcePath not found in full path\")\n",
    "\n",
    "    # Extract the base URI before the raw source path\n",
    "    base_uri = full_path[:idx]\n",
    "    detailPath = structurePath[idx+len(rawSourcePath):]\n",
    "\n",
    "    startleveltoAdd = detailPath.count('/') - '/date-date/Guid/name.parquet'.count('/')\n",
    "\n",
    "    # Construct the wildcard path\n",
    "    wildcard_path = f\"{base_uri}{raw_source_path}{'/*' * startleveltoAdd}/{snapshot_folder}/*/*.parquet\"\n",
    "    return wildcard_path\n",
    "\n",
    "def generateArrayOFPeriod(from_Month: int, to_month: int):\n",
    "    # Get today's date\n",
    "    today = datetime.today()\n",
    "\n",
    "    # Subtract one day\n",
    "    yesterday = today - timedelta(days=1)\n",
    "    first_day = yesterday.replace(day=1)\n",
    "\n",
    "    periodToLoad = []\n",
    "    if from_Month == to_month:\n",
    "        periodDate = first_day + relativedelta(months=to_month)\n",
    "        periodToLoad.append(periodDate.date())\n",
    "    else:\n",
    "        for i in range(from_Month, to_month+1):\n",
    "            periodDate = first_day + relativedelta(months=i)\n",
    "            periodToLoad.append(periodDate.date())\n",
    "\n",
    "    return periodToLoad\n",
    "\n",
    "\n",
    "def AddCapacityPauseColumn(dfsource):\n",
    "    # Define the schema for the JSON structure. In this version, only for Fabric billingtype\n",
    "    schema = StructType().add(\"BillingType\", StringType())\n",
    "\n",
    "    df_parsed = dfsource.withColumn(\"parsed_json\", from_json(col(\"x_SkuDetails\"), schema))\n",
    "\n",
    "    # Create the new column based on the condition\n",
    "    df_transformed = df_parsed.withColumn(\"CapacityPause\", when(col(\"parsed_json.BillingType\") == \"Capacity Pause/Delete Surcharge\", True).otherwise(False))\n",
    "\n",
    "    # Optionally drop the intermediate parsed column\n",
    "    df_final = df_transformed.drop(\"parsed_json\")\n",
    "\n",
    "    return df_final\n",
    "\n",
    "def AddBillingTypeColumn(dfsource):\n",
    "    # Define the schema for the JSON structure. In this version, only for Fabric billingtype\n",
    "    schema = StructType().add(\"BillingType\", StringType())\n",
    "\n",
    "    df_parsed = dfsource.withColumn(\"parsed_json\", from_json(col(\"x_SkuDetails\"), schema))\n",
    "\n",
    "    # Create the new column based on the condition\n",
    "    df_transformed = df_parsed.withColumn(\"BillingType\", col(\"parsed_json.BillingType\"))\n",
    "\n",
    "    # Optionally drop the intermediate parsed column\n",
    "    df_final = df_transformed.drop(\"parsed_json\")\n",
    "\n",
    "    return df_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ecff50-1936-4942-ad83-d833541a7b2d",
   "metadata": {
    "microsoft": {
     "language": "sparksql",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## STEP 1 Load Silver:\n",
    "Load into bronze table\n",
    "Identify context and prepare load in silver\n",
    "- Delete previous data\n",
    "- Clean date format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0cfa93-d2e2-4f77-9447-24068090eae5",
   "metadata": {
    "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-07-11T10:39:26.7108458Z\",\"execution_finish_time\":\"2025-07-11T10:39:30.117208Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-07-11T10:39:30.117208Z",
       "execution_start_time": "2025-07-11T10:39:26.7108458Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "61a88abb-278d-4bde-9091-5e90632cb382",
       "queued_time": "2025-07-11T10:39:22.4185495Z",
       "session_id": "f92ff0f1-c298-45e6-bda4-9ad94e766612",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 6,
       "statement_ids": [
        6
       ]
      },
      "text/plain": [
       "StatementMeta(, f92ff0f1-c298-45e6-bda4-9ad94e766612, 6, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "structurePath = find_first_parquet_file(rawSourcePath)\n",
    "periodsToLoad = generateArrayOFPeriod(fromMonth, toMonth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3b19339-fb7a-41a8-9deb-18d1ce43066f",
   "metadata": {
    "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-07-10T08:29:11.3535724Z\",\"execution_finish_time\":\"2025-07-10T08:29:23.4131426Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-07-10T08:29:23.4131426Z",
       "execution_start_time": "2025-07-10T08:29:11.3535724Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "46fdd5e9-d094-460f-9a34-8ffa17971a86",
       "queued_time": "2025-07-10T08:29:10.2168649Z",
       "session_id": "175f81b0-a6b8-4761-9ef7-d5ebf4bff478",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 67,
       "statement_ids": [
        67
       ]
      },
      "text/plain": [
       "StatementMeta(, 175f81b0-a6b8-4761-9ef7-d5ebf4bff478, 67, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Period : 2025-07-01\n",
      "Used path to load data: abfss://d7ae03b3-c53b-4ee6-af7e-0091be2e7cc4@onelake.dfs.fabric.microsoft.com/edea360e-6c6d-4761-aeca-d57df8bd7b91/Files/focuscost/*/*/20250701-20250731/*/*.parquet\n",
      "Table exists, snapshot will be clean.\n",
      "End Period : 2025-07-01\n"
     ]
    }
   ],
   "source": [
    "for per in periodsToLoad:\n",
    "    print(\"Start Period : \" + per.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    #drop staging table if exists\n",
    "    spark.sql(\"DROP TABLE IF EXISTS focus_staging\")\n",
    "\n",
    "    #generate storage path date part\n",
    "    fromFormatedDate = per.strftime(\"%Y%m%d\")\n",
    "    toFormatedDate = (per + relativedelta(months=1) + relativedelta(days=-1)).strftime(\"%Y%m%d\")\n",
    "    snapshot_folder = fromFormatedDate + \"-\" + toFormatedDate\n",
    "\n",
    "    wildcard = generate_wildcard_path(structurePath, rawSourcePath, snapshot_folder)\n",
    "    print(\"Used path to load data: \" + wildcard)\n",
    "\n",
    "    try:\n",
    "        df = spark.read.parquet(wildcard)\n",
    "        df.write.format('delta').saveAsTable(\"focus_staging\")\n",
    "\n",
    "        #identify period loaded\n",
    "        df = spark.sql(\"SELECT BillingPeriodStart FROM focus_staging LIMIT 1\")\n",
    "        value = df.first()['BillingPeriodStart']\n",
    "\n",
    "        #clean existing data in silver\n",
    "        if spark._jsparkSession.catalog().tableExists('Focus', \"focus\"):\n",
    "            print(\"Table exists, snapshot will be clean.\")\n",
    "            spark.sql(f\"DELETE FROM focus WHERE BillingPeriodStart = '{value}'\")\n",
    "\n",
    "        #Load data in silver\n",
    "        focus_staging_df = DeltaTable.forPath(spark,\"Tables/focus_staging\").toDF()\n",
    "        focus_staging_df.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable(\"focus\")\n",
    "\n",
    "    except AnalysisException as e:\n",
    "        if \"PATH_NOT_FOUND\" in str(e):\n",
    "            print(f\"Path not found: {wildcard}\")\n",
    "        else:\n",
    "            raise # re-raise if it's a different AnalysisException\n",
    "\n",
    "    print(\"End Period : \" + per.strftime(\"%Y-%m-%d\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841f3f2-1ac9-4aee-bc4f-e4d9095b6b99",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## STEP 2 Load Gold:\n",
    "\n",
    "- Filter on Fabric data only\n",
    "- Remove x_ column\n",
    "- Add FabricPause column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e36181-2317-4838-9c95-5ab2ba4761fc",
   "metadata": {
    "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-07-11T10:40:51.611355Z\",\"execution_finish_time\":\"2025-07-11T10:41:01.5519545Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-07-11T10:41:01.5519545Z",
       "execution_start_time": "2025-07-11T10:40:51.611355Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "666147ee-c2dc-41c7-b95b-f0451bcfd6e5",
       "queued_time": "2025-07-11T10:40:51.6101028Z",
       "session_id": "f92ff0f1-c298-45e6-bda4-9ad94e766612",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 8,
       "statement_ids": [
        8
       ]
      },
      "text/plain": [
       "StatementMeta(, f92ff0f1-c298-45e6-bda4-9ad94e766612, 8, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading Period(s) in '2025-01-01 00:00:00', '2025-02-01 00:00:00', '2025-03-01 00:00:00', '2025-04-01 00:00:00', '2025-05-01 00:00:00', '2025-06-01 00:00:00', '2025-07-01 00:00:00'\n",
      "Table exists, snapshot will be clean.\n",
      "Clean performed\n",
      "End Loading\n"
     ]
    }
   ],
   "source": [
    "# Preparation of predicate for all ingested periods\n",
    "date_condition = \", \".join([f\"'{date.strftime('%Y-%m-%d')} 00:00:00'\" for date in periodsToLoad])\n",
    "\n",
    "print(\"Start loading Period(s) in \" + date_condition)\n",
    "\n",
    "#clean existing data in silver\n",
    "if spark._jsparkSession.catalog().tableExists('Focus', \"focus_fabric\"):\n",
    "    print(\"Table exists, snapshot will be clean.\")\n",
    "    Delete_sql_query = f\"\"\"DELETE FROM focus_fabric WHERE BillingPeriodStart IN ({date_condition})\"\"\"\n",
    "    spark.sql(Delete_sql_query)\n",
    "    print(\"Clean performed\")\n",
    "\n",
    "x_columns_to_keep = ['x_SkuMeterName','x_SkuMeterSubcategory','x_ResourceGroupName']\n",
    "compute_columns_to_keep = [\"BillingType\",\"ChargePeriodStart_DateKey\",\"MeterKey\",\"CommitmentSavings\"]\n",
    "\n",
    "focus_df = DeltaTable.forPath(spark,\"Tables/focus\").toDF()\n",
    "Meters_df = DeltaTable.forPath(spark,\"Tables/meters\").toDF().select(\"Name_Lower\",\"MeterKey\")\n",
    "max_key = Meters_df.agg(max(\"MeterKey\")).collect()[0][0]\n",
    "\n",
    "# Get all column names that do NOT start with 'x_'\n",
    "columns_to_keep = [col for col in focus_df.columns if not col.startswith(\"x_\")]\n",
    "columns_to_keep = columns_to_keep + x_columns_to_keep + compute_columns_to_keep\n",
    "\n",
    "focus_df = focus_df.where(f\"\"\"ServiceName = 'Microsoft.Fabric' and BillingPeriodStart IN ({date_condition})\"\"\")\n",
    "focus_df = AddBillingTypeColumn(focus_df)\n",
    "\n",
    "#identify missing Meters in the referencial\n",
    "missing_Meters_df = focus_df.select(\"x_SkuMeterName\",\"ChargeDescription\",\"BillingType\") \\\n",
    "                            .withColumn(\"Name_Lower\",lower(\"x_SkuMeterName\")) \\\n",
    "                            .drop(\"x_SkuMeterName\") \\\n",
    "                            .dropDuplicates([\"Name_Lower\"]) \\\n",
    "                            .withColumn(\"Category\",when(col(\"ChargeDescription\") == \"Fabric Cap\",\"Fabric CU\").otherwise(col(\"ChargeDescription\"))) \\\n",
    "                            .drop(\"ChargeDescription\") \\\n",
    "                            .withColumn(\"State\",lit(\"Unknow\")) \\\n",
    "                            .withColumn(\"Main\",lit(\"FALSE\"))  \\\n",
    "                            .withColumn(\"Included\",when(col(\"BillingType\").isNotNull() & (col(\"BillingType\") != \"Capacity Pause/Delete Surcharge\"),lit(\"TRUE\")).otherwise(lit(\"FALSE\"))) \\\n",
    "                            .drop(\"BillingType\")\n",
    "\n",
    "missing_Meters_df = missing_Meters_df.join(Meters_df,\"Name_Lower\",\"leftouter\")\n",
    "missing_Meters_df = missing_Meters_df.where(missing_Meters_df.MeterKey.isNull())\n",
    "window_spec = Window.orderBy(\"Name_Lower\")\n",
    "missing_Meters_df = missing_Meters_df.withColumn(\"MeterKey\", row_number().over(window_spec) + max_key)\n",
    "\n",
    "missing_Meters_df.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable(\"Meters\")\n",
    "\n",
    "\n",
    "Meters_df = DeltaTable.forPath(spark,\"Tables/meters\").toDF()\n",
    "Meters_df = Meters_df.select(\"Name_Lower\",\"MeterKey\")\n",
    "focus_df = focus_df.withColumn(\"Name_Lower\", lower(\"x_SkuMeterName\")).join(Meters_df,\"Name_Lower\", \"leftouter\").drop(\"Name_Lower\") #retrieve MeterKey\n",
    "focus_df = focus_df.withColumn(\"ChargePeriodStart_DateKey\", date_format(\"ChargePeriodStart\", \"yyyyMMdd\").cast(\"int\"))\n",
    "focus_df = focus_df.withColumn(\"CommitmentSavings\", col(\"ContractedCost\") - col(\"EffectiveCost\"))\n",
    "focus_df = focus_df.select(columns_to_keep)\n",
    "\n",
    "focus_df.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable(\"focus_fabric\")\n",
    "\n",
    "print(\"End Loading\")\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "edea360e-6c6d-4761-aeca-d57df8bd7b91",
    "default_lakehouse_name": "FCA",
    "default_lakehouse_workspace_id": "d7ae03b3-c53b-4ee6-af7e-0091be2e7cc4",
    "known_lakehouses": [
     {
      "id": "edea360e-6c6d-4761-aeca-d57df8bd7b91"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

